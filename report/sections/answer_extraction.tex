After the passage retrieval a list of paragraphs is retrieved where the answer is likely exists. 
From these pieces of text the goal is to rank all the words and hopefully the right one comes out on top.
To find possible answers  decided to focus on nouns and proper nouns. 

\subsection{Rank nouns}

The passages/paragraphs retrieved with help of Lucene is assumed to frequently contain the right answer
because found paragraphs should be closely related to the question.

The nouns and proper nouns are extracted from all found paragraphs with the help of a Part of Speech (PoS) 
tagger, in our case Stagger \cite{stagger}.

From the list of passages we obtain scores for how well every paragraph fits our question, i.e the bm25 score. 
This is used together with the number of occurances of a noun to calculate the rank.
More precisely: For each noun that is found in any of the paragraphs we calculate the rank as follows:

\[ nounrank = \sum_{p\:\in\:paragraphs}bm25(p) \cdot c_p \]

where bm25(p) is the bm25 score of a paragraph and c is the number of occurances of the word in a paragraph

\subsection{Reranker}

Reranking the nouns further is done using machine learning and more specifically logistic regression.
A model is trained with our training set and then used to predict the best answer candidate from a question.

When training the model three feature vectors and a true/false value is used. 
The features vectors used is question words, answer words and question (predicted) categories, and the true/false
value determines if the answer matches the right one.


\subsection{Puncher}

To further improve the ranking we have experimented with a module we call the puncher. It simply boosts 
words with a matching category (stagger) to the predicted categories (libshorttext). 